---
title: "Analysis of Smoking Data (2011-2017)"
author: "Peter J. Ehmann"
date: "Due: 5/6/2019"
output: html_document
---

```{r setup, include = FALSE}
library(broom)
library(jsonlite)
library(knitr)
library(rvest)
library(tidyverse)
library(xml2)
opts_chunk$set(echo = FALSE)
```

<br>

# Part 1 - Acquire, clean, and format data (export as .csv).

<br>

#### You can retreive information about US state smoking data from the Centers for Disease Control (CDC) through the Socrata APA. The JSON-formatted data for smoking rates by state from 2011-2017 can be accessed from https://chronicdata.cdc.gov/resource/gx47-p4ij.json. A few columns of interest (renamed) are shown below. The smoking rate (%) and year are nested as 7x2 tibbles for each state.

```{r rates, warning = FALSE}
smoking_rates <- "https://chronicdata.cdc.gov/resource/gx47-p4ij.json" %>% 
  fromJSON() %>% 
  as_tibble() %>% 
  rename(state = locationdesc, abbr = locationabbr, year = year, percent = data_value) %>% 
  select(state, abbr, year, percent) %>% 
  group_by(state, abbr) %>% 
  nest(.key = smoking_rate) %>% 
  filter(abbr != "PR",
         abbr != "GU")
smoking_rates
```

<br>

#### Get state taxation data. JSON.

```{r tax}
tax <- "https://chronicdata.cdc.gov/resource/7uzt-fasa.json" %>% 
  fromJSON() %>% 
  as.data.frame()
```

<br>

#### Information about US state region classifications can be scraped from the main list in the HTML of https://simple.wikipedia.org/wiki/List_of_regions_of_the_United_States. The div, ul, and il tags can be used to extract each state's region and division (sub-region).

```{r scrape_wiki_html}
(
states_html <- read_html("https://simple.wikipedia.org/wiki/List_of_regions_of_the_United_States")
)

states <- states_html %>% 
  html_nodes(xpath = "//div/ul/li/ul/li/ul/li") %>% 
  html_text()

divisions <- states_html %>% 
  html_nodes(xpath = "//div/div/div/div/ul/li/ul/li") %>% 
  html_text()

regions <- states_html %>% 
  html_nodes(xpath = "//div/div/div/div/ul/li") %>% 
  html_text()
```

```{r extract_division}
division_names <- divisions %>% 
  str_extract(., "\\((.*)\\)") %>% 
  str_extract(., "[\\w+\\s?]+")

division_counts <- divisions %>% 
  str_count(., "\n")

division_list = ""
for (i in 1:length(division_names)) {
  division_list <- c(division_list, (rep(division_names[i], division_counts[i])))
}
```

```{r extract_region}
region_names <- regions %>% 
  .[1:4] %>% 
  str_extract(., "\\((.*)\\)") %>% 
  str_extract(., "[\\w+\\s?]+")

region_counts <- regions %>% 
  .[1:4] %>% 
  str_count(., "\n")

divisions_per_region <- regions %>% 
  .[1:4] %>% 
  str_count(., "Division")

region_list = ""
for (i in 1:length(region_names)) {
  region_list <- c(region_list, (rep(region_names[i], region_counts[i]-divisions_per_region[i])))
}
```

```{r states_table}
state_table <- as_tibble(data.frame(matrix(nrow = length(states), ncol = 3)))
colnames(state_table) <- c("state", "region", "division")
state_table[,1] <- states
state_table[,2] <- region_list[-1]
state_table[,3] <- division_list[-1]
state_table %>% arrange(state)
```

<br>

#### The X datasets are merged by*STATE and the nested tibbles are unnested.

```{r merge_data}
df_clean <- merge(smoking_rates, state_table, by = "state") %>%
  unnest()
```

#### The last step is to export the data as a .csv file which is posted in the GitHub repository.

```{r write_csv}
df_clean %>% write_csv("smoking_data.csv")
rm(list = ls(all = TRUE))
```

<br>

# Part 2 - Data visualization and statistics.

<br>

#### The cleaned data can be retreived from the GitHub repository at https://raw.githubusercontent.com/peter-ehmann/Data_Wrangling_Project_S2019/master/smoking_data.csv.

```{r import_clean_data, message = FALSE}
data <- read_csv("https://raw.githubusercontent.com/peter-ehmann/Data_Wrangling_Project_S2019/master/smoking_data.csv")
data
```

<br>

#### Display information about the packages used, their versions, and the version of R that was used.

```{r sessionInfo}
devtools::session_info()
```
